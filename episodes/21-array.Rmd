---
title: Parallelising with Job Arrays.
teaching: 15
exercises: 5
---

```{r, echo=FALSE}
# Source the external configuration script
source("load_config.R")
```

::::::::::::::::::::::::::::::::::::::: objectives

- Prepare a job submission script for an array job.

::::::::::::::::::::::::::::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::::: questions

- What are job arrays?
- What benefit does job arrays bring?
- What type of jobs would benefit from job arrays?

::::::::::::::::::::::::::::::::::::::::::::::::::


Parallelism is one of the primary tools we have to improve the performance of computational tasks. The simplest form of parallelism is to run the same job multiple times with different inputs. A more advanced form of parallelism is MPI, which is covered in the next episode. It is possible to use both these methods at the same time, using an array job to run multiple instances of software, which itself uses MPI.

Download the word frequency script from https://github.com/NewcastleRSE-Training/hpc-intro/blob/main/episodes/files/word-freq.sh

Run at command line with a small test file (/nobackup/proj/comet_training/ArrayJob/test-data.txt)

Write a batch script to call the word-freq.sh as single job and run using slurm (job_single_word-freq.sh) 
or download it from https://github.com/NewcastleRSE-Training/hpc-intro/blob/main/episodes/files/job_single_word-freq.sh


Update the batch sript to run on the first file of 4 text files 
named data.1 data.2 data.3 data.4 
downloaded from the Guteberg project (in /nobackup/proj/comet_training/ArrayJob/ - see make-data.sh to download again)

Write a batch script to call the word-freq.sh as an array job with 4 parallel jobs to process all 4 text files (job_array_word-freq.sh)
or download it from https://github.com/NewcastleRSE-Training/hpc-intro/blob/main/episodes/files/job_array_word-freq.sh

Check slurm.out files to see how quickly the jobs completed

```bash
`r config$remote$bash_shebang`
`r config$sched$comment` `r config$sched$flag$queue``r config$sched$partition`
`r config$sched$comment` `r config$sched$flag$name``r config$sched$job_name1`
`r config$sched$comment` `r config$sched$flag$nodes`1
`r config$sched$comment` `r config$sched$flag$tasks`1
`r config$sched$comment` `r config$sched$flag$cpu`1

# Do a word frequency analysis of the collected works of Shakespeare

DATA_FILE=data.1

echo "Starting word frequency analysis of $DATA_FILE"
echo "=============================================="

time cat $DATA_FILE | \
	sed s'/\ /\n/g' | \
	tr -c -d "[A-Za-z\n]" | \
	tr [A-Z] [a-z] | \
	sort | \
	strings -n 1 | \
	uniq -c | \
	sort -n > data.out

echo "====================================="
echo "Completed word analysis of $DATA_FILE"
```

:::::::::::::::::::::::::::::::::::::::: keypoints

- Stuff

::::::::::::::::::::::::::::::::::::::::::::::::::
